{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NGUYỄN TRẦN LÂM - 20016701 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import thư viện \n",
    "import pandas as pd\n",
    "import re\n",
    "from underthesea import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from joblib import dump, load\n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bài 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu được thu thập từ trang báo `vnexpress.net` <br> gồm các Label:\n",
    "- Chứng khoán\n",
    "- Doanh nghiệp\n",
    "- Ebank \n",
    "- Bóng đá \n",
    "- Khoa học "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Học đầu tư chứng khoán thế nào với người mới b...</td>\n",
       "      <td>Tôi mới tìm hiểu thị trường chứng khoán gần đâ...</td>\n",
       "      <td>Chứng khoán</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VN-Index lên mức cao nhất 9 tháng</td>\n",
       "      <td>VN-Index chốt phiên tại 1.129,38 điểm, tăng hơ...</td>\n",
       "      <td>Chứng khoán</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIG | Dòng tiền đổ mạnh vào cổ phiếu DIG</td>\n",
       "      <td>Sau phiên ATO, thị giá DIG nhảy vọt lên vùng 2...</td>\n",
       "      <td>Chứng khoán</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chứng khoán tăng phiên thứ hai liên tiếp</td>\n",
       "      <td>Chỉ số đại diện cho sàn TP HCM đóng cửa tại 1....</td>\n",
       "      <td>Chứng khoán</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chứng khoán lội ngược dòng</td>\n",
       "      <td>Mở cửa phiên hôm nay, chỉ số đại diện sàn HoSE...</td>\n",
       "      <td>Chứng khoán</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cổ phiếu Novaland gần chạm sàn</td>\n",
       "      <td>Như dự báo của giới phân tích, thị trường đối ...</td>\n",
       "      <td>Chứng khoán</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiền vào chứng khoán tăng trở lại</td>\n",
       "      <td>Sau khi chạm đáy vào cuối tháng 4, thanh khoản...</td>\n",
       "      <td>Chứng khoán</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chứng khoán tuần này đối mặt nhịp điều chỉnh</td>\n",
       "      <td>Thị trường vừa ghi nhận một tuần giao dịch run...</td>\n",
       "      <td>Chứng khoán</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chứng khoán đảo chiều giảm</td>\n",
       "      <td>Sáng nay, chỉ số đại diện cho sàn TP HCM tăng ...</td>\n",
       "      <td>Chứng khoán</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'Cổ phiếu chứng khoán kỳ vọng khởi sắc từ nay ...</td>\n",
       "      <td>Theo bà Nguyễn Ngọc Linh, Giám đốc tự doanh Ch...</td>\n",
       "      <td>Chứng khoán</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Học đầu tư chứng khoán thế nào với người mới b...   \n",
       "1                  VN-Index lên mức cao nhất 9 tháng   \n",
       "2           DIG | Dòng tiền đổ mạnh vào cổ phiếu DIG   \n",
       "3           Chứng khoán tăng phiên thứ hai liên tiếp   \n",
       "4                         Chứng khoán lội ngược dòng   \n",
       "5                     Cổ phiếu Novaland gần chạm sàn   \n",
       "6                  Tiền vào chứng khoán tăng trở lại   \n",
       "7       Chứng khoán tuần này đối mặt nhịp điều chỉnh   \n",
       "8                         Chứng khoán đảo chiều giảm   \n",
       "9  'Cổ phiếu chứng khoán kỳ vọng khởi sắc từ nay ...   \n",
       "\n",
       "                                             content     category  \n",
       "0  Tôi mới tìm hiểu thị trường chứng khoán gần đâ...  Chứng khoán  \n",
       "1  VN-Index chốt phiên tại 1.129,38 điểm, tăng hơ...  Chứng khoán  \n",
       "2  Sau phiên ATO, thị giá DIG nhảy vọt lên vùng 2...  Chứng khoán  \n",
       "3  Chỉ số đại diện cho sàn TP HCM đóng cửa tại 1....  Chứng khoán  \n",
       "4  Mở cửa phiên hôm nay, chỉ số đại diện sàn HoSE...  Chứng khoán  \n",
       "5  Như dự báo của giới phân tích, thị trường đối ...  Chứng khoán  \n",
       "6  Sau khi chạm đáy vào cuối tháng 4, thanh khoản...  Chứng khoán  \n",
       "7  Thị trường vừa ghi nhận một tuần giao dịch run...  Chứng khoán  \n",
       "8  Sáng nay, chỉ số đại diện cho sàn TP HCM tăng ...  Chứng khoán  \n",
       "9  Theo bà Nguyễn Ngọc Linh, Giám đốc tự doanh Ch...  Chứng khoán  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data.csv\", encoding='utf-8')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Tiền xử lý dữ liệu với Beautiful Soup, re,... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tôi mới tìm hiểu thị trường chứng khoán gần đây mọi thứ quá phức tạp nên tôi muốn học kỹ lĩnh vực này sau đó sẽ bỏ ít vốn ra thực hành chấp nhận lỗ rồi mới tính chuyện đầu tư lâu dài tôi muốn được chuyên gia tư vấn giúp lộ trình tham khảo từ việc học tập về chứng khoán cho đến giai đoạn thử thực hành và chính thức tham gia thị trường ở mỗi giai đoạn tôi cần tập trung hoặc chú ý những điều gì trần quang ngọc nhà đầu tư đang theo dõi thị trường tại một sàn giao dịch chứng khoán ở quận tp hcm ảnh quỳnh trần chuyên gia tư vấn chứng khoán nói chung và cổ phiếu nói riêng là kênh đầu tư rất hấp dẫn thu hút được nhiều nhà đầu tư ở mọi lứa tuổi đây là kênh đầu tư có nhiều lợi ích trong đó nổi bật nhất là tính thanh khoản có thể bắt đầu từ số vốn vừa và nhỏ ở đây tôi sẽ tạm hiểu nhu cầu của bạn là đầu tư vào cổ phiếu và mong muốn được biết thêm về lộ trình và cách học đầu tư cổ phiếu để tham gia thị trường thành công và hiệu quả bạn đã xác định đúng trong việc đầu tư vào kiến thức nhằm giúp bản thân đưa ra quyết định đúng đắn và phù hợp vậy việc học nên bắt đầu từ đâu cho đúng theo tôi nếu học mà không đi đôi với hành sẽ rất dễ tạo cảm giác chán nản khó tập trung do đó lời khuyên đầu tiên của tôi là bạn nên có một tài khoản chứng khoán và tập làm quen với những chức năng cơ bản trên thị trường vì người thầy tốt nhất với bạn chính là thị trường đừng đợi đến lúc học xong mới tham gia vì lúc đó có thể đã quá trễ và việc học là việc cả đời nhưng trước khi bắt đầu xuống tiền việc cần làm là xác định rõ khẩu vị rủi ro cho bản thân khẩu vị rủi ro là quan điểm mức độ chấp nhận của mỗi người về sự rủi ro khẩu vị rủi ro thường được xác định qua các yếu tố như lứa tuổi khả năng tài chính gia đình mức độ khẩu vị rủi ro sẽ quyết định sự an toàn cho nguồn vốn của bản thân và kỳ vọng sinh lợi ví dụ nếu đầu tư triệu đồng bạn sẽ chấp nhận mất bao nhiêu khi khoản đầu tư bị thua lỗ với độ rủi ro ở mức đã xác định bạn kỳ vọng sẽ thu về bao nhiêu phần trăm lợi nhuận để bù đắp cho những rủi ro có thể gặp phải khi đã xác định được khẩu vị rủi ro thời gian dành cho đầu tư khả năng tài chính và phương án dự phòng tài chính bước tiếp theo nên bắt đầu lựa chọn cho mình một số phương pháp và cách học hiệu quả một số phương pháp nổi bật là đầu tư giá trị đầu tư'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def processcing_text(text):\n",
    "    tweet = text\n",
    "    #lower\n",
    "    tweet = tweet.lower()\n",
    "    #convert any url link to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet)\n",
    "    #convert any @Username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+', 'AT_USER', tweet)\n",
    "\n",
    "    #Remove not alphanumeric symbols white spaces\n",
    "    tweet = re.sub(r'[^\\w]',' ', tweet)\n",
    "    #Removes # hashtag in front of a word\n",
    "    tweet = re.sub(r'#([\\w]+)', r'\\1', tweet)\n",
    "    tweet = re.sub(r'#([^\\s]+)',r'\\1',tweet)\n",
    "    #remove :( or :)\n",
    "    tweet = tweet.replace(':)','')\n",
    "    tweet = tweet.replace(':(','')\n",
    "    #remove numbers\n",
    "    tweet = ''.join([i for i in tweet if not i.isdigit()])\n",
    "    #remove multiple exclamation\n",
    "    tweet = re.sub(r'(!)\\1+', ' ', tweet)\n",
    "    #remove multiple question marks\n",
    "    tweet = re.sub(r'(\\?)\\1+','', tweet)\n",
    "    #remove multistop\n",
    "    tweet = re.sub(r'(\\.)\\1+','', tweet)\n",
    "    #Remove additional whitespace\n",
    "    tweet = re.sub(r'[\\s]+',' ', tweet)\n",
    "    tweet = re.sub(r'[\\n]+',' ', tweet)\n",
    "    row = tweet\n",
    "    return row\n",
    "\n",
    "df['content']=df['content'].apply(processcing_text)\n",
    "df.head(1)['content'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Tách từ (Tokenize) sử dụng thư viện pyvi hay underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tôi mới tìm_hiểu thị_trường_chứng_khoán gần đây mọi thứ quá phức_tạp nên tôi muốn học_kỹ lĩnh_vực này sau đó sẽ bỏ ít vốn ra thực_hành chấp_nhận lỗ rồi mới tính_chuyện đầu_tư lâu_dài tôi muốn được chuyên_gia tư_vấn giúp lộ_trình tham_khảo từ việc học_tập về chứng_khoán cho đến giai_đoạn thử thực_hành và chính_thức tham_gia thị_trường ở mỗi giai_đoạn tôi cần tập_trung hoặc chú_ý những điều gì trần_quang ngọc nhà_đầu_tư đang theo_dõi thị_trường tại một sàn giao_dịch chứng_khoán ở quận tp hcm ảnh quỳnh_trần chuyên_gia tư_vấn chứng_khoán nói_chung và cổ_phiếu nói_riêng là kênh đầu_tư rất hấp_dẫn thu_hút được nhiều nhà_đầu_tư ở mọi lứa tuổi đây là kênh đầu_tư có nhiều lợi_ích trong đó nổi_bật nhất là tính thanh_khoản có_thể bắt_đầu từ số vốn vừa và nhỏ ở đây tôi sẽ tạm hiểu nhu_cầu của bạn là đầu_tư vào cổ_phiếu và mong_muốn được biết thêm về lộ_trình và cách học đầu_tư cổ_phiếu để tham_gia thị_trường thành_công và hiệu_quả bạn đã xác_định đúng trong việc đầu_tư vào kiến_thức nhằm giúp bản_thân đưa ra quyết_định đúng_đắn và phù_hợp vậy việc học nên bắt_đầu từ đâu cho đúng theo tôi nếu học mà không đi_đôi với hành sẽ rất dễ tạo cảm_giác chán_nản khó tập_trung do_đó lời khuyên đầu_tiên của tôi là bạn nên có một tài_khoản chứng_khoán và tập làm_quen với những chức_năng cơ_bản trên thị_trường vì người thầy tốt nhất với bạn chính là thị_trường đừng đợi đến lúc học xong mới tham_gia vì lúc đó có_thể đã quá trễ và việc học là việc cả đời nhưng trước khi bắt_đầu xuống tiền việc cần làm là xác_định rõ khẩu_vị rủi_ro cho bản_thân khẩu_vị rủi_ro là quan_điểm mức_độ chấp_nhận của mỗi người về sự rủi_ro khẩu_vị rủi_ro thường được xác_định qua các yếu_tố như lứa tuổi khả_năng tài_chính gia_đình mức_độ khẩu_vị rủi_ro sẽ quyết_định sự an_toàn cho nguồn vốn của bản_thân và kỳ_vọng sinh_lợi ví_dụ nếu đầu_tư triệu đồng bạn sẽ chấp_nhận mất bao_nhiêu khi khoản đầu_tư bị thua_lỗ với độ rủi_ro ở mức đã xác_định bạn kỳ_vọng sẽ thu về bao_nhiêu phần_trăm lợi_nhuận để bù_đắp cho những rủi_ro có_thể gặp phải khi đã xác_định được khẩu_vị rủi_ro thời_gian dành cho đầu_tư khả_năng tài_chính và phương_án dự_phòng tài_chính bước tiếp_theo nên bắt_đầu lựa_chọn cho mình một_số phương_pháp và cách học hiệu_quả một_số phương_pháp nổi_bật là đầu_tư giá_trị đầu_tư'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from underthesea import word_tokenize\n",
    "\n",
    "\n",
    "def toke(text):\n",
    "    t=word_tokenize(text, format='text')\n",
    "    # t=word_tokenize(t)\n",
    "    return t\n",
    "\n",
    "df['content']=df['content'].apply(toke)\n",
    "df['content'].head(1).values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Trích xuất đặc trưng TF-IDF bằng thư viện sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49, 2670), (49,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df['content'].values\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(corpus)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['category'].values)\n",
    "X.toarray().shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Đánh giá bộ dữ liệu với giải thuật KNN bằng phương pháp 5-Fold (k-fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chứng khoán', 'Doanh nghiệp', 'Ebank'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2)  \n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_val)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Huấn luyện dữ liệu cho bài toán phân loại văn bản với tỷ lệ dữ liệu 8:2 (8 phần train, 2 phần test) sử dụng đặc trưng TF-IDF và 2 giải thuật bayes và SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train.toarray() , y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Tính độ đo F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of Naive Bayes:  0.7\n",
      "F1 score of SVM:  0.9\n"
     ]
    }
   ],
   "source": [
    "print('F1 score of Naive Bayes: ', f1_score(y_test, nb_predictions, average='micro'))\n",
    "print('F1 score of SVM: ', f1_score(y_test, svm_predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM có F1 score cao hơn so với Naive Bayes, cho thấy SVM có khả năng phân loại tốt hơn trên tập kiểm tra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Tính độ đo Accurary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Naive Bayes:  0.7\n",
      "Accuracy score of SVM:  0.9\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of Naive Bayes: ', accuracy_score(y_test, nb_predictions))\n",
    "print('Accuracy score of SVM: ', accuracy_score(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy của SVM cao hơn so với Naive Bayes, cho thấy SVM dự đoán chính xác hơn trên tập kiểm tra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Tính độ đo Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of Naive Bayes: \n",
      " [[0 1 0]\n",
      " [0 4 2]\n",
      " [0 0 3]]\n",
      "Confusion matrix of SVM: \n",
      " [[0 1 0]\n",
      " [0 6 0]\n",
      " [0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix of Naive Bayes: \\n', confusion_matrix(y_test, nb_predictions)) \n",
    "print('Confusion matrix of SVM: \\n', confusion_matrix(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM có nhiều trường hợp True Positives hơn và không có False Negatives nào, trong khi Naive Bayes có một số False Negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. So sánh kết quả các độ đo 6,7,8 với 2 giải thuật học máy ở trên\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dựa trên các độ đo F1 score, Accuracy và Confusion Matrix, mô hình SVM hiện có hiệu suất tốt hơn so với mô hình Naive Bayes trên tập kiểm tra cụ thể này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Lưu model với giải thuật đạt kết quả tốt nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(nb_classifier, 'nb_classifier.pkl')\n",
    "dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_nb_classifier = load('nb_classifier.pkl')\n",
    "loaded_tfidf_vectorizer = load('tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doanh nghiệp'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_text_to_label(text):\n",
    "    text = processcing_text(text)\n",
    "    text = toke(text)\n",
    "    text = loaded_tfidf_vectorizer.transform([text]).toarray()\n",
    "    label = loaded_nb_classifier.predict(text)\n",
    "    label_name = label_encoder.inverse_transform(label)\n",
    "    return label_name[0]\n",
    "\n",
    "text_test='Một vụ tai nạn giao thông thảm khốc xảy ra ở tân bình'\n",
    "predict_text_to_label(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bài 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 32)\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    " ' Hôm_nay tôi đi_học',\n",
    " ' Hôm_nay tôi đi_học ở trường',\n",
    " ' Hôm_nay tôi nghỉ ở nhà',\n",
    " ' Hôm_nay tôi có đi_học không?',\n",
    "]\n",
    "vectorizer = HashingVectorizer(n_features=2**5)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mỗi từ trong câu sẽ được băm thành một số theo một hàm băm cố định. Ví dụ, từ \"Hôm_nay\" có thể được băm thành 1, \"tôi\" có thể được băm thành 2, \"đi_học\" có thể được băm thành 3, và cứ tiếp tục.\n",
    "\n",
    "Đối với mỗi câu, các số băm này sẽ được sử dụng để xác định các features trong vectơ biểu diễn. Mỗi câu sẽ có một vectơ số có kích thước cố định, trong trường hợp này là 16 chiều.\n",
    "\n",
    "Các features trong vectơ được xác định dựa trên giá trị của các số băm. Ví dụ, nếu trong câu có từ \"đi_học\" được băm thành 3, thì có thể có một feature tại vị trí 3 trong vectơ.\n",
    "\n",
    "Kết quả của HashingVectorizer là một ma trận, trong đó mỗi hàng tương ứng với một câu trong corpus và mỗi cột tương ứng với một feature. Số trong mỗi ô của ma trận thể hiện mức độ xuất hiện của feature tương ứng trong câu tương ứng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bài 3: Sử dụng HashVectorizer thay cho đặc trưng TF-IDF ở bài 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49, 16384), (49,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_vec = HashingVectorizer(n_features=2**14)\n",
    "corpus = df['content'].values\n",
    "X = hash_vec.fit_transform(corpus)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['category'].values)\n",
    "X.toarray().shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of Naive Bayes:  0.7\n",
      "F1 score of SVM:  0.7\n",
      "Accuracy score of Naive Bayes:  0.7\n",
      "Accuracy score of SVM:  0.7\n",
      "Confusion matrix of Naive Bayes: \n",
      " [[0 1 0]\n",
      " [0 4 2]\n",
      " [0 0 3]]\n",
      "Confusion matrix of SVM: \n",
      " [[0 1 0]\n",
      " [1 4 1]\n",
      " [0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train.toarray() , y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test.toarray())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "svm_predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "print('F1 score of Naive Bayes: ', f1_score(y_test, nb_predictions, average='micro'))\n",
    "print('F1 score of SVM: ', f1_score(y_test, svm_predictions, average='micro'))\n",
    "print('Accuracy score of Naive Bayes: ', accuracy_score(y_test, nb_predictions))\n",
    "print('Accuracy score of SVM: ', accuracy_score(y_test, svm_predictions))\n",
    "print('Confusion matrix of Naive Bayes: \\n', confusion_matrix(y_test, nb_predictions)) \n",
    "print('Confusion matrix of SVM: \\n', confusion_matrix(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
